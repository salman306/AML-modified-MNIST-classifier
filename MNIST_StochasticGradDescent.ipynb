{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the functions needed to run the neural net__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## activation function\n",
    "def act_func(a, switch_ = 2):\n",
    "    if switch_ == 1: # linear activation\n",
    "        g = a\n",
    "    elif switch_ == 2: # sigmoid activation\n",
    "        g = 1.0 / (1.0 + np.exp(-1.0 * a))\n",
    "    elif switch_ == 3: # tanh() activation\n",
    "        g = np.tanh(a)\n",
    "    elif switch_ == 4: # ReLU activation\n",
    "        g = a.copy()\n",
    "        g[g<0] = 0\n",
    "    return g\n",
    "\n",
    "# derivative of the activation function wrt input\n",
    "def der_act_func(x, switch_ = 2):\n",
    "    if switch_ == 1: # linear activation\n",
    "        g = np.zeros(np.shape(x))+1\n",
    "    elif switch_ == 2: # sigmoid activation\n",
    "        g =  x * (1.0-x)\n",
    "    elif switch_ == 3: # tanh() activation\n",
    "        g = 1 - x**2\n",
    "    elif switch_ == 4: # ReLU activation\n",
    "        g = a.copy()\n",
    "        g[g<0] = 0\n",
    "        g[g>0] = 1\n",
    "    return g\n",
    "\n",
    "## neural net itself\n",
    "def neur_net(x, w_list, b, num_lay):\n",
    "    h_list = []\n",
    "    # set input as the first layer ([1, N])\n",
    "    h = x\n",
    "    h_list.append(h)\n",
    "    #### for each layer ([1, N+H])\n",
    "    for lay in range(num_lay-1):\n",
    "        # neuron pre-activation\n",
    "        a = b[lay] + np.dot(w_list[lay].T, h)\n",
    "\n",
    "        # activation function for layer 1\n",
    "        h = act_func(a)\n",
    "        h_list.append(h)\n",
    "\n",
    "    #pre-activation for output layer  (N+H+1)\n",
    "    lay = num_lay-1\n",
    "    a_out = b[lay] + np.dot(w_list[lay].T, h)\n",
    "\n",
    "    # activation function for output layer\n",
    "    f1 = act_func(a_out)\n",
    "#     print('sigmoid act')\n",
    "#     print(f1)\n",
    "    f = softmax(a_out)\n",
    "#     print('softmax act')\n",
    "#     print(f)\n",
    "    h_list.append(f)\n",
    "    return f, h_list#, f1\n",
    "\n",
    "# initialize weights in the correct shape\n",
    "def init_weights(num_neur_per_lay):\n",
    "    w_list = []\n",
    "#     np.random.seed(1)\n",
    "    for i in range(len(num_neur_per_lay)-1):\n",
    "    # initialize the weights so that they're in the right format\n",
    "        w = 2 * np.random.random((num_neur_per_lay[i], num_neur_per_lay[i+1])) - 1\n",
    "        w_list.append(w)\n",
    "#     print(w_list)\n",
    "    return w_list\n",
    "\n",
    "# update the weights\n",
    "def update_w(error, outp, inp, weight, alpha):\n",
    "    # calculate the error in output, this on its own goes for bias correction\n",
    "    del_out = error * der_act_func(outp)\n",
    "    # mulitply it by the input, this comes from the partial derivate wrt the weights\n",
    "    del_w = np.dot(inp, del_out.T)\n",
    "    # calculate error that we're going to propagate to the previous layer\n",
    "    prev_err = np.dot(weight, del_out )\n",
    "    return weight + alpha * del_w, prev_err, del_out # update\n",
    "\n",
    "# initialize the biases\n",
    "def init_bias(num_neur_per_lay, nonzeros=False):\n",
    "    b_list = []\n",
    "    np.random.seed(1)\n",
    "    for i in range(len(num_neur_per_lay)-1):\n",
    "    # initialize the weights so that they're in the right format\n",
    "        if nonzeros:\n",
    "            w = 2 * np.random.random((num_neur_per_lay[i+1],1)) - 1\n",
    "            b_list.append(w)\n",
    "        else:\n",
    "            w = 2 * np.zeros((num_neur_per_lay[i+1],1)) - 1\n",
    "            b_list.append(w)     \n",
    "    return b_list\n",
    "\n",
    "# softmax for the output layer (not yet used)\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x),0,keepdims=True)\n",
    "\n",
    "## loss function, basically error\n",
    "def error_func(output, y_label, is_squared=True):\n",
    "    if is_squared:\n",
    "        error = np.mean( (y_label - output)**2 / 2)\n",
    "    else:\n",
    "        error = np.mean(- y_label * np.nan_to_num(np.log(output)) - (1 - y_label) * np.nan_to_num(np.log(1-output)))\n",
    "    return error\n",
    "\n",
    "## derivative of the loss function\n",
    "def error_der(output, y_label, is_squared=True):\n",
    "    if is_squared:\n",
    "        error = y_label - output\n",
    "    else:\n",
    "        error = np.nan_to_num(np.divide(y_label, output) + np.divide((1 - y_label), (1 - output)))\n",
    "        error = np.divide(y_label, output) - np.divide((1 - y_label), (1 - output))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load input and label__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(2, 4)\n",
      "(784, 36850)\n",
      "(10, 36850)\n",
      "(28038, 784)\n",
      "(28038, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import NeuralNets\n",
    "\n",
    "x = np.array([[0,0,1],[1,1,1],[1,0,1],[0,1,1]]).T\n",
    "y = np.array([[0,0],[1,0],[1,0],[0,0]]).T\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))\n",
    "\n",
    "X = mnist.train.images#[0:10000]\n",
    "Y = mnist.train.labels#[0:10000]\n",
    "bool_0 = (Y == np.array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])).all(1)\n",
    "bool_1 = (Y == np.array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])).all(1)\n",
    "bool_2 = (Y == np.array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])).all(1)\n",
    "bool_3 = (Y == np.array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])).all(1)\n",
    "bool_4 = (Y == np.array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]])).all(1)\n",
    "bool_5 = (Y == np.array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]])).all(1)\n",
    "bool_6 = (Y == np.array([[ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]])).all(1)\n",
    "bool_7 = (Y == np.array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]])).all(1)\n",
    "bool_8 = (Y == np.array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]])).all(1)\n",
    "bool_9 = (Y == np.array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])).all(1)\n",
    "bool_ = (bool_0 | bool_1 | bool_2 | bool_3 | bool_4)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X[bool_], Y[bool_], test_size=0.33, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "###### SUPER important to have them in the right format/dimension\n",
    "x_train = x_train.T\n",
    "x_test=x_test.T\n",
    "y_train=y_train.T\n",
    "y_test=y_test.T\n",
    "# print(x_train)\n",
    "# print(y_train)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "# print(X.T)\n",
    "# print(Y.T)\n",
    "print(np.shape(X[bool_]))\n",
    "print(np.shape(Y[bool_]))\n",
    "# print(len(mnist.train.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSf0/k3EU2BPqPLMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11974a6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just plot one\n",
    "import matplotlib.pyplot as plt\n",
    "# print(x_train.T[0])\n",
    "print(np.shape(x_train.T[0].reshape(28,28)))\n",
    "plt.imshow(x_train.T[0].reshape(28,28), cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array([[0,0,1],[1,1,1],[1,0,1],[0,1,0]]).T\n",
    "y_train = np.array([[0,1],[1,1],[1,1],[0,0]]).T\n",
    "x_test = np.array([[1,0,0]]).T\n",
    "y_test = np.array([[1,0]]).T\n",
    "\n",
    "\n",
    "x_train = np.array([[0,0,1,0],[0,0,1,0],[0,1,0,0],[1,0,0,0]]).T\n",
    "y_train = np.array([[0,0,1,0],[0,0,1,0],[0,1,0,0],[1,0,0,0]]).T\n",
    "x_test = np.array([[1,0,0,0]]).T\n",
    "y_test = np.array([[1,0,0,0]]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initialize weights and biases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Number of nodes per layers. First layer is the input, last is the output \n",
      "[784 300  10]\n"
     ]
    }
   ],
   "source": [
    "num_inputs = int(x_train.shape[0])\n",
    "num_outputs = y_train.shape[0]\n",
    "print(num_outputs)\n",
    "###### modify this if you want to have more layer or change the #of nodes per layer\n",
    "num_neur_per_lay = np.array([num_inputs,300,num_outputs])\n",
    "## e.g. num_neur_per_lay = np.array([num_inputs,300,100,num_outputs]), \n",
    "## gives you 2 hidden layer with 300 nodes in the first one and 100 in the second one\n",
    "\n",
    "print 'Number of nodes per layers. First layer is the input, last is the output '\n",
    "print num_neur_per_lay\n",
    "num_lay = len(num_neur_per_lay)-1\n",
    "\n",
    "# initialize weights based on input and output format\n",
    "w_list = init_weights(num_neur_per_lay)\n",
    "# initialize biases based on input and output format\n",
    "b = init_bias(num_neur_per_lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "[784 300  10]\n",
      "Training error with initial weights = 0.128219604881\n",
      "Training accuracy with initial weights = 0.781818181818\n",
      "Test accuracy with random weights = 0.778071625344\n",
      "Start backprop with alpha = 1e-05\n",
      "After 0 out of 1000 backprop. Training error = 0.127174610155, test error = 0.0162463663867\n",
      "Training accuracy = 0.784016282225, test accuracy = 0.780055096419\n",
      "After 10 out of 1000 backprop. Training error = 0.119581719655, test error = 0.0154110997586\n",
      "Training accuracy = 0.79565807327, test accuracy = 0.791680440771\n",
      "After 20 out of 1000 backprop. Training error = 0.113552845504, test error = 0.0147323845985\n",
      "Training accuracy = 0.804721845319, test accuracy = 0.801487603306\n",
      "After 30 out of 1000 backprop. Training error = 0.108521381211, test error = 0.0141595806877\n",
      "Training accuracy = 0.812157394844, test accuracy = 0.809972451791\n",
      "After 40 out of 1000 backprop. Training error = 0.104231893427, test error = 0.0136682086401\n",
      "Training accuracy = 0.818588873813, test accuracy = 0.815757575758\n",
      "After 50 out of 1000 backprop. Training error = 0.100510155495, test error = 0.0132400718166\n",
      "Training accuracy = 0.825780189959, test accuracy = 0.821707988981\n",
      "After 60 out of 1000 backprop. Training error = 0.0972335915153, test error = 0.012861839568\n",
      "Training accuracy = 0.830800542741, test accuracy = 0.826666666667\n",
      "After 70 out of 1000 backprop. Training error = 0.0943136583349, test error = 0.0125237965267\n",
      "Training accuracy = 0.835169606513, test accuracy = 0.831570247934\n",
      "After 80 out of 1000 backprop. Training error = 0.0916849441822, test error = 0.0122187835516\n",
      "Training accuracy = 0.839240162822, test accuracy = 0.835592286501\n",
      "After 90 out of 1000 backprop. Training error = 0.0892981539033, test error = 0.0119414312435\n",
      "Training accuracy = 0.843934871099, test accuracy = 0.838622589532\n",
      "After 100 out of 1000 backprop. Training error = 0.0871154368034, test error = 0.0116876266184\n",
      "Training accuracy = 0.847571234735, test accuracy = 0.842369146006\n",
      "After 110 out of 1000 backprop. Training error = 0.0851072032403, test error = 0.0114541399867\n",
      "Training accuracy = 0.851017639077, test accuracy = 0.845785123967\n",
      "After 120 out of 1000 backprop. Training error = 0.0832499209403, test error = 0.011238367058\n",
      "Training accuracy = 0.854029850746, test accuracy = 0.849201101928\n",
      "After 130 out of 1000 backprop. Training error = 0.0815245682245, test error = 0.0110381564662\n",
      "Training accuracy = 0.856743554953, test accuracy = 0.852672176309\n",
      "After 140 out of 1000 backprop. Training error = 0.079915533865, test error = 0.0108516976063\n",
      "Training accuracy = 0.859782903664, test accuracy = 0.855482093664\n",
      "After 150 out of 1000 backprop. Training error = 0.0784098248843, test error = 0.0106774474146\n",
      "Training accuracy = 0.862062415197, test accuracy = 0.858126721763\n",
      "After 160 out of 1000 backprop. Training error = 0.0769964895652, test error = 0.0105140804353\n",
      "Training accuracy = 0.864721845319, test accuracy = 0.860991735537\n",
      "After 170 out of 1000 backprop. Training error = 0.0756661925348, test error = 0.0103604524853\n",
      "Training accuracy = 0.867272727273, test accuracy = 0.862975206612\n",
      "After 180 out of 1000 backprop. Training error = 0.074410898139, test error = 0.0102155726107\n",
      "Training accuracy = 0.869579375848, test accuracy = 0.864297520661\n",
      "After 190 out of 1000 backprop. Training error = 0.0732236313621, test error = 0.0100785805162\n",
      "Training accuracy = 0.871858887381, test accuracy = 0.866170798898\n",
      "After 200 out of 1000 backprop. Training error = 0.0720982945995, test error = 0.00994872786632\n",
      "Training accuracy = 0.873568521031, test accuracy = 0.867933884298\n",
      "After 210 out of 1000 backprop. Training error = 0.0710295249812, test error = 0.0098253624405\n",
      "Training accuracy = 0.875332428765, test accuracy = 0.869641873278\n",
      "After 220 out of 1000 backprop. Training error = 0.0700125814499, test error = 0.00970791448012\n",
      "Training accuracy = 0.877530529172, test accuracy = 0.871074380165\n",
      "After 230 out of 1000 backprop. Training error = 0.0690432539556, test error = 0.00959588480604\n",
      "Training accuracy = 0.87921302578, test accuracy = 0.87217630854\n",
      "After 240 out of 1000 backprop. Training error = 0.0681177893259, test error = 0.00948883446834\n",
      "Training accuracy = 0.880705563094, test accuracy = 0.873663911846\n",
      "After 250 out of 1000 backprop. Training error = 0.0672328299213, test error = 0.00938637579829\n",
      "Training accuracy = 0.882333785617, test accuracy = 0.875151515152\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ec2c96c7cd8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Feed example through network to compute output with updated weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneur_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# For the output layer, compute the derivative of error and correction with updated weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-440531b88394>\u001b[0m in \u001b[0;36mneur_net\u001b[0;34m(x, w_list, b, num_lay)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# activation function for layer 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mh_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-440531b88394>\u001b[0m in \u001b[0;36mact_func\u001b[0;34m(a, switch_)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mswitch_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# sigmoid activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mswitch_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# tanh() activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # # initialize weights and biases if you want to restart\n",
    "# w_list = init_weights(num_neur_per_lay)\n",
    "# #bias\n",
    "# b = init_bias(num_neur_per_lay )\n",
    "print('Before')\n",
    "print(num_neur_per_lay)\n",
    "# print(w_list)\n",
    "# print(b)\n",
    "[np.shape(w_) for w_ in w_list]\n",
    "\n",
    "alpha = 0.00001\n",
    "\n",
    "N_epoch = 1000\n",
    "\n",
    "###### True - use squared error as loss function; False - use log-likelihood as loss function\n",
    "is_squared_loss = False\n",
    "\n",
    "# Feed example through network to compute output with random weights\n",
    "o, h_list = neur_net(x_train, w_list, b, num_lay)\n",
    "\n",
    "# For the output layer, compute the error and correction\n",
    "# out_err = (y_train-o)\n",
    "out_der_err = error_der(o, y_train, is_squared_loss)\n",
    "# compute the output error\n",
    "out_err = error_func(o, y_train, is_squared_loss)\n",
    "\n",
    "print 'Training error with initial weights = '+str(out_err)\n",
    "print 'Training accuracy with initial weights = '+str(sum(np.argmax(o,0) == np.argmax(y_train,0)) / float(np.shape(o)[1]))\n",
    "o_test2, h_list2 = neur_net(x_test, w_list, b, num_lay)\n",
    "# print(o_test2)\n",
    "print 'Test accuracy with random weights = ' + str(sum(np.argmax(o_test2,0) == np.argmax(y_test,0)) / float(np.shape(o_test2)[1]))\n",
    "\n",
    "print 'Start backprop with alpha = ' +str(alpha)\n",
    "\n",
    "for i in range(N_epoch):\n",
    "\n",
    "    new_weight, prev_err, del_b = update_w(out_der_err, h_list[-1], h_list[-2], w_list[-1], alpha)\n",
    "    # update weight for output layer with alpha already included\n",
    "    w_list[-1] = new_weight\n",
    "    # update bias for output layer\n",
    "    b[-1] = b[-1] + alpha * np.mean(del_b,1,keepdims=True)\n",
    "    \n",
    "    # For the hidden layers, compute the error and correction\n",
    "    for j in range(num_lay-1):\n",
    "        new_weight, prev_err, del_b = update_w(prev_err, h_list[-2-j], h_list[-3-j], w_list[-2-j], alpha)\n",
    "        # update weight for hidden layer with alpha already included\n",
    "        w_list[-2-j] = new_weight\n",
    "        # update bias for hidden layers\n",
    "        b[-2-j] = b[-2-j] + alpha * np.mean(del_b,1,keepdims=True)\n",
    "        \n",
    "    # Feed example through network to compute output with updated weights\n",
    "    o, h_list = neur_net(x_train, w_list, b, num_lay)\n",
    "    \n",
    "    # For the output layer, compute the derivative of error and correction with updated weights\n",
    "    out_der_err = error_der(o, y_train, is_squared_loss)\n",
    "    # compute the output error\n",
    "    out_err = error_func(o, y_train, is_squared_loss)\n",
    "#     out_err = (y_train - o)\n",
    "    \n",
    "    \n",
    "    if (i% 10) == 0:\n",
    "        # neural net on test set\n",
    "        o_test, h_list_test = neur_net(x_test, w_list, b, num_lay)\n",
    "\n",
    "        # test error\n",
    "        test_out_err = error_func(o_test, y_test, True)\n",
    "        \n",
    "        print 'After '+ str(i)+' out of ' + str(N_epoch) + ' backprop. Training error = '+str(out_err)+\\\n",
    "            ', test error = ' + str(test_out_err)\n",
    "        print 'Training accuracy = '+str(sum(np.argmax(o,0) == np.argmax(y_train,0)) / float(np.shape(o)[1]))+\\\n",
    "            ', test accuracy = ' + str(sum(np.argmax(o_test,0) == np.argmax(y_test,0)) / float(np.shape(o_test)[1]))\n",
    "\n",
    "print(o)\n",
    "print(w_list)\n",
    "# print(b)\n",
    "# print(x)\n",
    "# [np.shape(w_) for w_ in w_list]\n",
    "# print(o_test[:,3])\n",
    "# print(np.argmax(o_test[:,3],0))\n",
    "# print(y_test[:,3])\n",
    "# print(np.argmax(y_test[:,3],0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "[[0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 1 0 0]\n",
      " [0 0 0 0]]\n",
      "[2 2 1 0]\n",
      "pred\n",
      "[[ 0.25017745  0.25015237  0.25018604  0.2501771 ]\n",
      " [ 0.24996657  0.24974358  0.25010234  0.24995687]\n",
      " [ 0.24968433  0.24997873  0.24952314  0.24969512]\n",
      " [ 0.25017166  0.25012532  0.25018848  0.25017091]]\n",
      "[0 0 3 0]\n",
      "Training error = 0.0937536169098\n",
      "Training accuracy = 0.25\n",
      "[[ 0.2501771 ]\n",
      " [ 0.24995687]\n",
      " [ 0.24969512]\n",
      " [ 0.25017091]]\n",
      ", test accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "out_err = error_func(o, y_train, True)\n",
    "print('labels')\n",
    "print(y_train)\n",
    "print(np.argmax(y_train,0))\n",
    "print('pred')\n",
    "print(o)\n",
    "print(np.argmax(o,0))\n",
    "print 'Training error = '+str(out_err)\n",
    "print 'Training accuracy = '+str(sum(np.argmax(o,0) == np.argmax(y_train,0)) / float(np.shape(o)[1]))\n",
    "o_test2, h_list2 = neur_net(x_test, w_list, b, num_lay)\n",
    "print(o_test2)\n",
    "print ', test accuracy = ' + str(sum(np.argmax(o_test2,0) == np.argmax(y_test,0)) / float(np.shape(o_test2)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.916290731874155"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 1 0 0]\n",
      " [0 0 0 0]]\n",
      "o\n",
      "[[ nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan]]\n",
      "0.0\n",
      "[[ nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan]]\n"
     ]
    }
   ],
   "source": [
    "o, h_list = neur_net(x_train, w_list, b, num_lay)\n",
    "print(y_train)\n",
    "# print(o_reg)\n",
    "print('o')\n",
    "print(o)\n",
    "# print(np.sum(o,0,keepdims=True))\n",
    "\n",
    "print(error_func(o, y_train, False))\n",
    "\n",
    "print(error_der(o, y_train, False))\n",
    "# print('SSE')\n",
    "# print(- (y_train - o))\n",
    "\n",
    "# print('log-likelihood')\n",
    "# print(- np.divide(y_train, o))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD9CAYAAACoXlzKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7BKJRGJm/D8coiLJ+g/DxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119cdfdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a = np.arange(-2,2,0.2)\n",
    "lab = ('linear activation','sigmoid activation','tanh() activation','ReLU activation')\n",
    "for i in range(4):#[3]:\n",
    "    print i\n",
    "    plt.subplot(211)\n",
    "    plt.plot(a, act_func(a, i+1), label=lab[i])\n",
    "    plt.subplot(212)\n",
    "    plt.plot(a, der_act_func(a, i+1), label=lab[i])\n",
    "plt.subplot(211)\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log-likelihood (also called cross-entropy\n",
    "error function)\n",
    "y*log(o)\n",
    "y/o*do/dw\n",
    "y/o*o*(1-o)*dz/dw\n",
    "y*(1-o)*dz/dw\n",
    "\n",
    "sum squared error function\n",
    "1/2*(y-o)^2\n",
    "-(y-o)*do/dw\n",
    "-(y-o)*o*(1-o)*dz/dw\n",
    "(y-o)*o*(1-o)*dz/dw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I've run 1000 nodes and it reached 75% accuracy, but again, this is with squared error, not log-likelihood yet. That should be better for sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Not needed__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new output [1, 0, 0]\n",
      "Result[[ 0.99986946]\n",
      " [ 0.17011654]]\n"
     ]
    }
   ],
   "source": [
    "print 'new output [1, 0, 0]'\n",
    "o, h_list = neur_net(np.array([[1,0,0]]).T, w_list, b, num_lay)\n",
    "print 'Result' + str(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00922196  0.00777619  0.00653753 -0.0077548 ]\n",
      " [-0.00541096 -0.00078916 -0.00237167 -0.00180415]]\n",
      "[[ 0.00922196  0.00777619  0.00653753  0.0077548 ]\n",
      " [ 0.00541096  0.00078916  0.00237167  0.00180415]]\n",
      "0.00520830384613\n"
     ]
    }
   ],
   "source": [
    "out_err = (y-o)\n",
    "print(out_err)\n",
    "# np.mean(\n",
    "print(np.abs(out_err))\n",
    "print(np.mean(np.abs(out_err)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000000001"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.mean(np.abs(test_out_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test==o_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(o_test[:,:3],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18150,)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.argmax(o_test,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(o_test,0) == np.argmax(y_test,0)) / np.shape(o_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(o_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 5, ..., 2, 4, 9])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.84744453  2.84744453  2.84744453  2.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]\n",
      " [ 3.84744453  3.84744453  3.84744453  3.84744453]]\n",
      "[0 0 0 0]\n",
      "[[ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "[2 2 0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(o_test[:,:4])\n",
    "print(-np.log(softmax(o_test[:,:4])))\n",
    "print(np.argmax(softmax(o_test[:,:4]),0))\n",
    "print(y_test[:,:4])\n",
    "print(np.argmax(y_test[:,:4],0))\n",
    "np.argmax(o_test[:,:4],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
